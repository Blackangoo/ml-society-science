{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"Alcohol\", \"Malic acid\", \"Ash\", \"Alcalinity of ash\",\n",
    "    \"Magnesium\", \"Total phenols\", \"Flavanoids\", \"Nonflavanoid phenols\",\n",
    "    \"Proanthocyanins\", \"Color intensity\", \"Hue\",\n",
    "    \"OD280/OD315 of diluted wines\", \"Proline\"]\n",
    "target = 'Class'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a Data Set\n",
    "\n",
    "This is a rather simple dataset. It is easy to get a good performance with even very simple classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pandas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e6848c4c766e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pandas' is not defined"
     ]
    }
   ],
   "source": [
    "df = pandas.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data', names=[target] + features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
       "0      1    14.23        1.71  2.43               15.6        127   \n",
       "1      1    13.20        1.78  2.14               11.2        100   \n",
       "2      1    13.16        2.36  2.67               18.6        101   \n",
       "3      1    14.37        1.95  2.50               16.8        113   \n",
       "4      1    13.24        2.59  2.87               21.0        118   \n",
       "\n",
       "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
       "0             5.64  1.04                          3.92     1065  \n",
       "1             4.38  1.05                          3.40     1050  \n",
       "2             5.68  1.03                          3.17     1185  \n",
       "3             7.80  0.86                          3.45     1480  \n",
       "4             4.32  1.04                          2.93      735  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fc835e78310>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc836141c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for c, d in df.groupby('Class'):\n",
    "    d.Alcohol.plot.hist(label=c, alpha=0.6)\n",
    "plt.legend()\n",
    "plt.xlabel('Alcohol Content')\n",
    "plt.title('Alcohol Content per Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Feature Importance by Achieved Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named model_selection",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0c3fc4c2fb6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named model_selection"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we can specify values for a complete set $\\{ f(x) \\mid x \\in X\\}$ with the syntax  `[f[i] for x in X]` as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [KNeighborsClassifier(n_neighbors=5).fit(train_data[[f]], train_data[target]) for f in features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_scores = [accuracy_score(train_data[target], m.predict(train_data[[f]])) for m, f in zip(models, features)]\n",
    "plt.barh(range(len(features)), train_scores)\n",
    "plt.yticks(range(len(features)), features)\n",
    "plt.gcf().set_size_inches(10, 5)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [accuracy_score(test_data[target], m.predict(test_data[[f]])) for m, f in zip(models, features)]\n",
    "plt.barh(range(len(features)), scores)\n",
    "plt.yticks(range(len(features)), features)\n",
    "plt.gcf().set_size_inches(10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which k Should You Choose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = pandas.DataFrame(StandardScaler().fit_transform(df[features]), columns=features)\n",
    "df_scaled[target] = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_s, test_data_s = train_test_split(df_scaled, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, _ = train_data_s.shape\n",
    "N_test, _ = test_data_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = range(1, 100)\n",
    "models = [KNeighborsClassifier(n_neighbors=k).fit(train_data_s[features], train_data_s[target]) for k in ks]\n",
    "train_scores = [accuracy_score(train_data_s[target], m.predict(train_data_s[features])) for m in models]\n",
    "test_scores = [accuracy_score(test_data_s[target], m.predict(test_data_s[features])) for m in models]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test score performance\n",
    "\n",
    "Were we omniscient, we could just look at the test scores. These the performance of model $\\lambda(k, D_T)$ on $D^*$. From the plot below we can see that almost any value below 90 or so works pretty well. We also see a discrepancy between the maximising values in the training and test set. The best value for the training set is simply $k = 1$. However good test set values occur starting from $k=3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogx(ks, train_scores, ks, test_scores);\n",
    "plt.legend([\"Train\", \"Test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation to choose $k$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbor_ks = range(1, 100)\n",
    "untrained_models = [KNeighborsClassifier(n_neighbors=k) for k in neighbor_ks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold_scores = [cross_val_score(estimator=m, X=df_scaled[features], y=df_scaled[target], cv=10) for m in untrained_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_fold_scores)\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_xv_scores = [s.mean() for s in k_fold_scores] \n",
    "plt.errorbar(neighbor_ks, mean_xv_scores, yerr=[s.std() for s in k_fold_scores])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let us compare the best values for training test and cross validation\n",
    "\n",
    "import numpy\n",
    "knn_best_k_xv = numpy.asarray(mean_xv_scores).argmax()\n",
    "knn_best_k_train = numpy.asarray(train_scores).argmax()\n",
    "knn_best_k_test = numpy.asarray(test_scores).argmax()\n",
    "print(ks[knn_best_k_xv], ks[knn_best_k_train], ks[knn_best_k_test])\n",
    "plt.semilogx(ks, train_scores, ks, test_scores, ks, mean_xv_scores)\n",
    "plt.legend([\"Train\", \"Test\", \"XV\"])\n",
    "\n",
    "# Let's select the best model on the basis of the XV score, as we must, since the 'test' result is invisible to us\n",
    "knn_best_model_xv = models[knn_best_k_xv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrapping\n",
    "\n",
    "Bootsrapping is useful for two things. First, remember that even though the test score is an /independent/ measurement of an algorithm's performance, it is /not/ the actual expected performance. At best, it's an unbiased estimate of performance. Hence, we'd like to have some way to calculate a likely performance range from the test data. Bootstrapping can help: by taking multiple samples of the test set and calculating performance on each one, we obtain an empirical distribution of scores.\n",
    "\n",
    "Secondly, we can use it to tell us something about the sensitivity of our algorithm. In particular, by taking multiple samples from the training data, we can end up with multiple models. If the models are only slightly different, then the algorithm is more stable and we can be more confident in its predictions. This also allows us to generate probabilistic predictions from deterministic classification algorithms, by simply averaging predictions from multiple bootstrapped predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.utils # we can use sklearn.utils.resample to bootstrap\n",
    "n_bootstrap_samples = 1000 # the more samples we take the better our distributional estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are going to estimate how sensitive is the test result to the test data\n",
    "bootstrap_test_score = numpy.zeros(n_bootstrap_samples)\n",
    "\n",
    "# For each bootstrap sample, we get a different model. There is no need to save the model, as we just want the score on the test set.\n",
    "for t in range(n_bootstrap_samples):\n",
    "    bootstrap_test_sample = sklearn.utils.resample(test_data_s, replace=True, n_samples = N_test)\n",
    "    bootstrap_test_score[t] = accuracy_score(bootstrap_test_sample[target], knn_best_model_xv.predict(bootstrap_test_sample[features]))\n",
    "\n",
    "plt.hist(bootstrap_test_score)\n",
    "plt.title(\"Bootstrapped test scores for best kNN model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are going to estimate the sensitivity of the algorithm to the training data\n",
    "bootstrap_score = numpy.zeros(n_bootstrap_samples)\n",
    "\n",
    "# For each bootstrap sample, we get a different model. There is no need to save the model, as we just want the score on the test set.\n",
    "for t in range(n_bootstrap_samples):\n",
    "    bootstrap_sample = sklearn.utils.resample(train_data_s, replace=True, n_samples = N)\n",
    "    bootstrap_model = KNeighborsClassifier(n_neighbors=knn_best_k_xv).fit(bootstrap_sample[features], bootstrap_sample[target])\n",
    "    bootstrap_score[t] = accuracy_score(test_data_s[target], bootstrap_model.predict(test_data_s[features]))\n",
    "plt.hist(bootstrap_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_score.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
