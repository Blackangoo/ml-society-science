%% This is a shortened version of the notes
\documentclass[a4paper,twoside]{book}
\usepackage{geometry}
\usepackage[notheorems]{beamerarticle}

\makeindex

\mode<presentation>{
  % \useinnertheme{rectangles}
  %\useoutertheme{infolines}
  % \usecolortheme{crane}
  % \usecolortheme{rose}
}
\input{../preamble}

\begin{document}


%\includeonly{causality}
\title{Machine learning in science and society}
\subtitle{From automated science to beneficial artificial intelligence}
\author[C. Dimitrakakis]{Christos Dimitrakakis}


\maketitle

\include{preface}

\tableofcontents


\include{ml-intro}
\include{privacy} %data bases


\chapter{Fairness}
\label{ch:fairness}
\only<article>{
  When machine learning algorithms are applied at scale, it can be difficult to imagine what their effects might be. In this part of the course, we consider notions of fairness as seen through the prism of conditional independence and meritocracy. The first notion requires that we look deeper into directed graphical models.
}
\input{fairness}


\chapter{Simple decision problems}
\label{ch:decision-problems}
\only<article>{This chapter deals with simple decision problems, whereby a decision maker (DM) makes a simple choice among many. In some of this problems the DM has to make a decision after first observing some side-information. Then the DM uses a \emph{decision rule} to assign a probability to each possible decision for each possible side-information. However, designing the decision rule is not trivial, as it relies on previously collected data. A higher-level decision includes choosing the decision rule itself. The problems of classification and regression fall within this framework. While most steps in the process can be automated and formalised, a lot of decisions are actual design choices made by humans. This creates scope for errors and misinterpretation of results.

In this chapter, we shall formalise all these simple decision problems from the point of view of statistical decision theory. The first question is, given a real world application, what type of decision problem does it map to? Then, what kind of machine learning algorithms can we use to solve it? What are the underlying assumptions and how valid are our conclusions? 
}

\input{decision-problems} % decision hierarchies
\input{bayes} % Bayesian inference
\input{ann} % linear models and stochastic gradient descent
\input{knn}  % knn, reproducability and bootstrapping
\input{naive-bayes} % naive Bayes classifiers

\chapter{Reproducibility}
\label{ch:reproducibility}
\input{reproducibility}



\chapter{Causality}
\label{ch:causality}
\include{causality}

\chapter{Experiment design}
\label{ch:bandit}
\include{experiment-design}

%\include{clustering}
%\include{networks}
%\include{hmm}
%\include{rnn}

\printindex

\appendix

\include{graphical-models}



\bibliographystyle{plainnat}
\bibliography{../bibliography}


\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-engine: xetex
%%% TeX-master: "book"
%%% End:
